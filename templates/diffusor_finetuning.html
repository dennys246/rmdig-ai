{% extends "base.html" %}

{% block title %}Fine-tuning | RMDig {% endblock %}

{% block content %}

<div class="py-16 px-4 md:px-8 max-w-6xl mx-auto dark:bg-gray-900 dark:text-gray-100">
  <div>
    <h2 class="text-4xl font-bold mb-4 text-indigo-600 dark:text-indigo-400 text-center">
      Practice Fine-Tuning <br>Diffusion Models
    </h2>

    <p class="mb-4">
      Fine-tuning Diffusion Models is both science and craftsmanship. This guide walks you from the conceptual
      building blocks to hands-on recipes for stabilizing and improving synthesis quality.
      We'll use the <a href="https://github.com/dennys246/coreDiffusor" class="font-semibold text-indigo-300 hover:text-indigo-600">coreDiffusor</a>
      and the <a href="/snowpack_dataset" class="font-semibold text-indigo-300 hover:text-indigo-600">Rocky Mountain snowpack dataset</a> as a concrete example.
    </p><br><br>
    
    <nav class="mb-8">
      <h2 class="text-xl font-bold">Table of Contents</h2>
      <ul class="list-disc pl-6 space-y-1 text-indigo-400">
        <li><a href="#cli" class="hover:text-indigo-600">Getting Started</a></li>
        <li><a href="#model" class="hover:text-indigo-600">Model Structure</a></li>
        <li><a href="#hyperparameters" class="hover:text-indigo-600">Hyperparameters (with recommended ranges)</a></li>
        <li><a href="#practice" class="hover:text-indigo-600">Hands-On Practice</a></li>
        <li><a href="#finetuning" class="hover:text-indigo-600">Fine-Tuning Strategies</a></li>
        <li><a href="#metrics-monitoring" class="hover:text-indigo-600">Metrics & Monitoring</a></li>
        <li><a href="#troubleshooting" class="hover:text-indigo-600">Troubleshooting</a></li>
        <li><a href="#references" class="hover:text-indigo-600">Further Reading & References</a></li>
      </ul>
    </nav>

    <!-- CLI -->
    <section id="cli" class="mb-8">
      <h1 class="text-indigo-300 text-2xl font-bold text-center">Getting Started</h1>
      <div class="mt-6 space-y-4">
        <p class="font-bold">Start by installing coreDiffusor, a diffusion backbone ready to be fine-tuned!</p>
        <div class="w-full bg-black text-white text-sm font-mono overflow-x-auto py-6 px-6 copy-container relative">
          <button class="copy-btn absolute top-2 right-2 text-xs bg-gray-700 hover:bg-gray-600 px-2 py-1 rounded">Copy</button>
<pre><code>
git clone https://github.com/dennys246/coreDiffusor.git
cd coreDiffusor
pip install -e .
</code></pre>
        </div>

        <p class="font-bold">Train from scratch</p>
        <div class="w-full bg-black text-white text-sm font-mono overflow-x-auto py-6 px-6 copy-container relative">
          <button class="copy-btn absolute top-2 right-2 text-xs bg-gray-700 hover:bg-gray-600 px-2 py-1 rounded">Copy</button>
<pre><code>
corediff --mode train
</code></pre>
        </div>

        <p class="font-bold">Explore different configuration, e.g. increase U-Net depth and learning rate:</p>
        <div class="w-full bg-black text-white text-sm font-mono overflow-x-auto py-6 px-6 copy-container relative">
          <button class="copy-btn absolute top-2 right-2 text-xs bg-gray-700 hover:bg-gray-600 px-2 py-1 rounded">Copy</button>
<pre><code>
corediff --mode train --unet_depth 4 --lr 5e-4
</code></pre>
        </div>

        <p class="font-bold">Generate images with your trained model</p>
        <div class="w-full bg-black text-white text-sm font-mono overflow-x-auto py-6 px-6 copy-container relative">
          <button class="copy-btn absolute top-2 right-2 text-xs bg-gray-700 hover:bg-gray-600 px-2 py-1 rounded">Copy</button>
<pre><code>
corediff --mode generate --checkpoint keras/corediffusor/diffusor.keras --n_samples 64
</code></pre>
        </div>

        <p class="mt-3 text-sm text-gray-600 dark:text-gray-400">
          Run <code>corediff --help</code> to list every tunable hyperparameter, checkpoint flags, and data paths.
        </p>
      </div>
    </section>

    <!-- MODEL -->
    <section id="model" class="mb-8">
      <h1 class="text-indigo-300 text-2xl font-bold text-center">Model Structure</h1>
      <div class="mt-6 space-y-4">
        <h3 class="font-semibold">High-level view</h3>
        <p>
          A diffusion model gradually denoises random noise into data samples using a <strong>U-Net backbone</strong>
          conditioned on timestep embeddings. Fine-tuning adapts the noise schedule, U-Net capacity, and conditioning
          (e.g. class labels, text prompts) to new datasets and tasks.
        </p>

        <h3 class="font-semibold">U-Net (in depth)</h3>
        <ul class="list-disc pl-6">
          <li><strong>Input:</strong> noised image + timestep + optional conditioning.</li>
          <li><strong>Downsampling path:</strong> convolutional blocks with residual connections, GroupNorm, and non-linearities.</li>
          <li><strong>Bottleneck:</strong> multi-head self-attention and residual layers.</li>
          <li><strong>Upsampling path:</strong> mirror of downsampling with skip connections.</li>
          <li><strong>Output:</strong> predicted noise or denoised image depending on parameterization.</li>
        </ul>

        <h3 class="font-semibold">Noise Schedule</h3>
        <ul class="list-disc pl-6">
          <li><strong>Linear / cosine schedules:</strong> control how noise is added during training.</li>
          <li><strong>β range:</strong> defines the variance schedule. Fine-tuning often involves adjusting this for sharper or smoother outputs.</li>
        </ul>
      </div>
    </section>

    <!-- HYPERPARAMETERS -->
    <section id="hyperparameters" class="mb-8">
      <h1 class="text-indigo-300 text-2xl font-bold text-center">Hyperparameters</h1>
      <div class="mt-6 space-y-4">
        <p class="mb-2">Below are common tunable parameters and guidance for how to change them and why.</p>

        <dl class="divide-y divide-gray-700 bg-gray-800 p-4 rounded">
          
          <div class="grid grid-cols-4 gap-4 font-semibold text-gray-100 bg-gray-800 p-2 rounded-t">
            <div>Hyperparameter</div>
            <div>CLI call</div>
            <div>Default</div>
            <div>Description</div>
          </div>

          <div class="py-3 grid grid-cols-4 gap-4">
            <div class="font-mono text-sm">Learning Rate</div>
            <div class="font-mono text-sm text-gray-300">--lr</div>
            <div class="text-gray-300">1e-4</div>
            <div>Typical range 1e-5–1e-4. Lower for larger datasets, higher for fast adaptation.</div>
          </div>

          <div class="py-3 grid grid-cols-4 gap-4">
            <div class="font-mono text-sm">Batch Size</div>
            <div class="font-mono text-sm text-gray-300">--batch_size</div>
            <div class="text-gray-300">32</div>
            <div>Larger batches stabilize gradients but require more memory. Scale LR accordingly.</div>
          </div>

          <div class="py-3 grid grid-cols-4 gap-4">
            <div class="font-mono text-sm">U-Net Depth</div>
            <div class="font-mono text-sm text-gray-300">--unet_depth</div>
            <div class="text-gray-300">3</div>
            <div>Controls number of down/upsampling stages. More depth → higher capacity, slower training.</div>
          </div>

          <div class="py-3 grid grid-cols-4 gap-4">
            <div class="font-mono text-sm">Timesteps</div>
            <div class="font-mono text-sm text-gray-300">--timesteps</div>
            <div class="text-gray-300">1000</div>
            <div>Number of diffusion steps during training. Higher → smoother denoising, but slower sampling.</div>
          </div>

          <div class="py-3 grid grid-cols-4 gap-4">
            <div class="font-mono text-sm">Sampling Steps</div>
            <div class="font-mono text-sm text-gray-300">--steps</div>
            <div class="text-gray-300">50</div>
            <div>Steps used at inference. Fewer steps = faster but blurrier outputs. Common: 20–100.</div>
          </div>

          <div class="py-3 grid grid-cols-4 gap-4">
            <div class="font-mono text-sm">Guidance Scale</div>
            <div class="font-mono text-sm text-gray-300">--guidance_scale</div>
            <div class="text-gray-300">7.5</div>
            <div>Higher values strengthen conditioning (e.g., prompts) but can reduce diversity.</div>
          </div>

        </dl>

        <p class="mt-3 text-sm text-gray-600 dark:text-gray-400">
          <strong>Rule of thumb:</strong> change one hyperparameter at a time and run for a small number of epochs to see its effect.
        </p>
      </div>
    </section>

    <!-- PRACTICE -->
    <section id="practice" class="mb-8">
      <h1 class="text-indigo-300 text-2xl font-bold text-center">Hands-On Practice</h1>
      <div class="mt-6 space-y-4">
        <h3 class="font-semibold">Project: coreDiffusor — practical recipes</h3>
        <p>Use these stepwise recipes on the Rocky Mountain snowpack dataset.</p>

        <h4 class="font-semibold">Quick sanity run (few epochs)</h4>
        <ol class="list-decimal pl-6">
          <li>Install & clone repository (see Getting Started above).</li>
          <li>Run a 10–20 epoch trial to check pipeline and confirm denoising:
            <div class="w-full bg-black text-white text-sm font-mono overflow-x-auto py-4 px-4 copy-container relative my-3">
              <pre><code>corediff --mode train --epochs 20 --batch_size 32 --lr 1e-4</code></pre>
            </div>
          </li>
          <li>Inspect generated samples in <code>synthetics/</code> and logs.</li>
        </ol>

        <h4 class="font-semibold">Faster convergence with fewer timesteps</h4>
        <ol class="list-decimal pl-6">
          <li>Try reducing training timesteps while keeping inference steps high.</li>
          <li>Example:
            <div class="w-full bg-black text-white text-sm font-mono overflow-x-auto py-4 px-4 copy-container relative my-3">
              <pre><code>corediff --mode train --timesteps 500 --steps 50</code></pre>
            </div>
          </li>
        </ol>

        <h4 class="font-semibold">Transfer learning & progressive unfreeze</h4>
        <ol class="list-decimal pl-6">
          <li>Load pretrained checkpoint: <code>--pretrained path/to/weights.pt</code></li>
          <li>Freeze early layers and fine-tune top layers with small LR:
            <div class="w-full bg-black text-white text-sm font-mono overflow-x-auto py-4 px-4 copy-container relative my-3">
              <pre><code>corediff --mode train --checkpoint keras/corediffusor/diffusor.keras --lr 5e-5</code></pre>
            </div>
          </li>
          <li>After stable progress, gradually unfreeze more layers and lower LR.</li>
        </ol>
      </div>
    </section>

    <!-- FINETUNING -->
    <section id="finetuning" class="mb-8">
      <h1 class="text-indigo-300 text-2xl font-bold text-center">Fine-Tuning Strategies</h1>
      <div class="mt-6 space-y-4">
        <h3 class="font-semibold">Balance training cost and sample quality</h3>
        <ul class="list-disc pl-6">
          <li><strong>Adjust learning rate:</strong> too high → divergence; too low → slow progress.</li>
          <li><strong>Reduce timesteps:</strong> faster training at some quality tradeoff.</li>
          <li><strong>Use EMA weights:</strong> stabilize inference by maintaining exponential moving averages of parameters.</li>
        </ul>

        <h3 class="font-semibold">Transfer Learning & Warm-Starts</h3>
        <p>
          Instead of training from scratch, initialize from pretrained weights and fine-tune only parts of the U-Net.
        </p>

        <h3 class="font-semibold">Progressive growing & resolution scaling</h3>
        <p>
          Train at lower resolution, then fine-tune at higher resolution. Reduces instability and speeds early learning.
        </p>

        <h3 class="font-semibold">Regularization tricks</h3>
        <ul class="list-disc pl-6">
          <li>Dropout inside U-Net bottleneck.</li>
          <li>Noise augmentation of inputs.</li>
          <li>Smaller guidance scale to avoid overfitting prompts.</li>
        </ul>
      </div>
    </section>

    <!-- REFERENCES -->
    <section id="references" class="mb-12">
      <h1 class="text-indigo-300 text-2xl font-bold text-center">Further Reading & References</h1>
      <div class="mt-6 space-y-3 text-sm">
        <p class="text-gray-700 dark:text-gray-300">
          This guide condenses widely used strategies for diffusion models. For deeper dives:
        </p>
        <ul class="list-disc pl-6">
          <li>Denoising Diffusion Probabilistic Models (Ho et al.)</li>
          <li>Improved Denoising Diffusion (Nichol & Dhariwal)</li>
          <li>Classifier-Free Guidance</li>
          <li>Latent Diffusion Models (Rombach et al.)</li>
          <li>DDIM Sampling</li>
        </ul>
      </div>
    </section>
  </div>
</div>

{% endblock %}