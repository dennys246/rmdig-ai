{% extends "base.html" %}

{% block title %}Snowpack Dataset | RMDig {% endblock %}

{% block content %}
        
<div class="py-16 px-4 md:px-8 max-w-6xl mx-auto bg-gray-900 text-gray-100">
    <div class="items-center">
        <h2 class="chalk-text text-4xl text-center font-bold mb-4 text-indigo-600 text-indigo-400">Rocky Mountain<br>Snowpack Dataset</h2>
        <figure class="float-left mr-6 mb-4 w-64">
            <img src="{{ url_for('static', filename='img/snow_profile_2.jpeg') }}"
                alt="Snow profile magnified"
                class="rounded-lg shadow-lg w-full">
            <figcaption class="text-sm text-gray-600 mt-2 text-center">
                Snow profile magnified
            </figcaption>
            
        </figure>
        <strong class="text-indigo-400">~1500 snowpack samples</strong> from <strong class="text-indigo-400">two visual modalities</strong> were collected using a novel mini-coring method developed by Denny Schaedig.
        Each sample is captured in a <strong class="text-indigo-400">chronological order</strong> and can be related in time and space to weather, geographical, and site data. Our hope is to make the uniquely
        collected snowpack samples a means to explore next generation computer vision concepts to assist in avalanche risk predicion, or really whatever peaks your interest!<br><br>
        <br><br><figure class="float-left mr-6 mb-4 w-64">
        <img src="{{ url_for('static', filename='img/core_1_split.JPG') }}"
            alt="Snow profile magnified"
            class="rounded-lg shadow-lg w-full">
        <figcaption class="text-sm text-gray-600 mt-2 text-center">
            Snow mini-core that split in half
        </figcaption>
        </figure>

        The <a href="/snowgan"><strong class="text-indigo-400 hover:text-indigo-800">snowGAN</strong></a> and <a href = "/corediff" class="text-indigo-400 hover:text-indigo-800 font-bold">coreDiffusor</a> 
        are our first steps in exploring these modalities and we are currently building AvAI, an AI predicting avalanche risk by embedding both the snowGAN and coreDiffusor
        alongside weather timeseries to improve avalanche prediction. Aside from this we hope people interested in machine learning can use this dataset to explore 
        machine learning itself, whether it be predicting avalanche risk or generating high resolution artificial images of snow.
        <br><br><br>
            <div class="w-full">
                <div style="padding:56.25% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/1086662296?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture; clipboard-write; encrypted-media" style="position:absolute;top:0;left:0;width:100%;height:100%;" title="snowgan_snowpack_intro_denny_schaedig"></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>
            <p class="mt-2 text-center text-indigo-200 text-indigo-200 italic">
                Overview of the Rocky Mountain Snowpack dataset and the snowGAN.
            </p>
            </div> <br><br>
            <h1 class = "text-2xl text-center font-bold text-indigo-400">Accessing the Dataset</h1><br>
            The dataset is stored in <a href = "https://huggingface.co/datasets/dennys246/rocky_mountain_snowpack" class = "text-indigo-400 hover:text-indigo-600 font-bold">Hugging Face</a> and can 
            be downloaded directly from pythons huggingface_hub library. You do not have to create an account, however it is recommended to 
            create one and explore everything Hugging Face has to offer at <a href = "www.huggingface.co">huggingface.co</a>. Who knows,
            you may find youself wanting to upload a model you created in no time!
            
    <div>
    <p class="text-lg text-gray-700 text-gray-300 leading-relaxed mb-4">
        <br>You can easily load the dataset in no time through Hugging Face's datasets library...

<div class="w-full bg-black text-white text-sm font-mono overflow-x-auto py-6 px-6">
<pre><code class="language-python"><span class="text-purple-300">from</span> datasets <span class="text-purple-300">import</span> load_dataset

<span class="text-gray-300"># Load dataset references through git lfs for low-memory access</span>
dataset = load_dataset(<span class="text-green-300">"rmdig/rocky_mountain_snowpack"</span>)
</code></pre></div><br>
You can also download the dataset through git and update it with periodic pulls.
You will need to install lfs.<br>
</p>
</div><br>

<div class="w-full bg-black text-white text-sm font-mono overflow-x-auto py-6 px-6">
<pre><code>git clone https://huggingface.co/datasets/RMDig/rocky_mountain_snowpack
</code></pre></div><br>

Alternatively you could download the dataset through python through Hugging Face's snapshot_download function, but this can be difficult to version control. <br>
<br>
<div class="w-full bg-black text-white text-sm font-mono overflow-x-auto py-6 px-6">
<pre><code class="language-python"><span class="text-purple-300">from</span> huggingface_hub <span class="text-purple-300">import</span> snapshot_download

<span class="text-gray-300"># Download snowpack dataset locally</span>
snapshot_download(
    repo_id=<span class="text-green-300">"rmdig/rocky_mountain_snowpack"</span>,
    repo_type=<span class="text-green-300">"dataset"</span>,
    local_dir=<span class="text-green-300">"path/to/local/dir/"</span>)
</code></pre></div>
    </p></div>

    <div>
        <p><br>
            Once you have downloaded the data you will find number of folders containing snowpack data
            in various forms...
        </p>
        <section>
            <br>
        <pre>
        ğŸ”ï¸ rocky_mountain_snowpack
        â”£ ğŸ“‚ preprocessed <span class="text-gray-300"># Contains the fully preprocessed snowpack images</span>
        â”ƒ  â”— ğŸ“‚ cores <span class="text-gray-300"># Contains images of the snow cores</span>
        â”ƒ  â”— ğŸ“‚ magnified-profiles <span class="text-gray-300"># Contains magnified images of snowpack</span>
        â”ƒ  â”— ğŸ“‚ profiles <span class="text-gray-300"># Contains non-magnified images of snowpack</span>
        â”ƒ  â”— ğŸ“‚ written_labels <span class="text-gray-300"># Contains images of segmented labels used for determining location</span>
        â”£ ğŸ“‚ raw <span class="text-gray-300"># Contains raw images of snowpack collected from the rocky mountains using the mini-coring method </span>
        â”ƒ  â”— ğŸ“‚ magnified-profiles <span class="text-gray-300"># Contains magnified images of snowpack</span>
        â”ƒ  â”— ğŸ“‚ crystal_cards <span class="text-gray-300"># Contains images of unsegmented crystal cards</span>
        â”£ ğŸ“‚ metadata <span class="text-gray-300"># Metadata of the dataset stored in JSONL files</span>
        â”ƒ  â”— ğŸ“„ raw.jsonl <span class="text-gray-300"># Metadata for all raw images</span>
        â”ƒ  â”— ğŸ“„ preprocessed.jsonl <span class="text-gray-300"># Metadata for all preprocessed images</span>
        â”ƒ  â”— ğŸ“„ train.jsonl <span class="text-gray-300"># Metadata on suggested train split of the dataset</span>
        â”ƒ  â”— ğŸ“„ test.jsonl <span class="text-gray-300"># Metadata on suggested test split of the dataset</span>
        â”ƒ  â”— ğŸ“„ validation.jsonl <span class="text-gray-300"># Metadata on suggested validation split of the dataset</span>
        â”£ ğŸ“œ LICENSE.txt <span class="text-gray-300"># CC-by-4.0 license</span>
        â”— ğŸ“œ README.md <span class="text-gray-300"># Dataset guide, read!</span>
        </pre>
        </section>
    </div>
    <div>
        The fully segmented and preprocess data will be within the preprocessed folders
        like rocky_mountain_snowpack/preprocessed/magnified_profiles. Labels for each image can be found
         within the JSONL files found in the metadata folder (i.e. rocky_mountain_snowpack/metadata/preprocessed.jsonl). 
         Each image is attached spatially and temporally to the other images, especially across the datatypes cores, magnified profiles,
         and profiles. <br><br>
        This dataset was collected with a method that allows you to related each image
        within the dataset to all the other images in the dataset, alongside environmental
        features like  world outside of the image! Each image is attached to
        a specific time and location, alongsige it's location in the snowpack, allowing you to
        relate important timeseries to the data such as temperature, snowfall, or avalanch risk
        predictions from the Colorado Avalanche Information Center. Alongside this a rich amount of
        other data is collected at each site to create a 
        <a href ='https://huggingface.co/datasets/rmdig/rocky_mountain_snowpack#labels' class = 'font-bold text-indigo-400 hover:text-indigo-800'>comprehensive labeling</a> of each image.
    </div>
    <div>
        <br><img src="{{ url_for('static', filename='img/example_crystalcard.JPG') }}"
            alt="Example crystal card"
            class="float-left mr-6 mb-4 w-96 rounded-lg shadow-lg">
        For example, the label for this crystal card indicates this image was collected
        from the 1st site, in the 1st column, in the 4th core, and we are picturing the
        1st segment. If we looked at the label for the image we would see these same labels
         attached to the image in the metadata alongside the following information
        <div>
            <ul class = 'bullet-list'>
                <li>Datatype</li>
                <li>Avalanches spotted</li>
                <li>Wind loading</li>
                <li>Snowpack depth</li>
                <li>Core depth</li>
                <li>Slope face</li>
                <li>Slope angle</li>
                <li>Air temperature</li>
                <li>Core temperature</li>
            </ul>
        </div>
        Using this information we can train an AI to do so many things! So far as mentioned I've built 
        two generative models to try and learn the features of the datatypes themselves, through generative AI.<br><br>
        Using these same pre-trained models, or your own model you've built from scratch, we could leverage machine 
        learning to train all kinds of AI. Most importantly we could try and predict the avalanche risk, each image
        has a label for avalanches spotted nearby attached. If we trained an AI to predict this, then simply outputted
        the number of avalanches it could be a metric of avalanche activity.<br><br>
    </div>
        </div>
    </div>
  </div>
</div>

{% endblock %}